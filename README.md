# âœï¸ Gemma3 LLM Blog Generator App
ğŸ” *Local LLM â€¢ Blog Generation â€¢ Ollama â€¢ LangChain â€¢ Streamlit*

## ğŸš€ Tech Stack & Domains
![Python](https://img.shields.io/badge/Python-3.x-blue?logo=python)
![LLM](https://img.shields.io/badge/LLM-Gemma3%201B-brightgreen)
![Ollama](https://img.shields.io/badge/Runtime-Ollama-black)
![LangChain](https://img.shields.io/badge/Framework-LangChain-purple)
![Streamlit](https://img.shields.io/badge/UI-Streamlit-red?logo=streamlit)
![Domain](https://img.shields.io/badge/Domain-NLP%20%26%20Content%20Generation-navy)

---

## ğŸ“˜ Overview
This project is a **local LLM-based blog generator application** built using **Gemma3 (1B)** running via **Ollama**.

Users can generate blog content by providing a topic or brief input. The system allows control over **word count**, **target audience**, and **system prompt mode**, making the generated content more aligned with the intended readers.

All generation happens locally without relying on cloud APIs.

---

## ğŸ¯ Problem Statement
Content creation often requires time, writing skill, and audience awareness. Existing tools mostly depend on cloud-based LLMs, which introduce cost, latency, and privacy concerns.

This project provides:
- Fully local blog generation  
- Audience-aware content creation  
- Custom system prompt control  

Without external API dependency.

---

## ğŸ’¼ Use Cases
| Use Case | Description |
|--------|-------------|
| âœï¸ Blog Writing | Generate structured blog posts from short inputs |
| ğŸ“ Education | Create student-friendly or research-focused content |
| ğŸ§‘â€ğŸ« Teaching | Produce explanations tailored for teachers |
| ğŸ§ª Experimentation | Test prompt engineering with local LLMs |

---

## ğŸ§  Blog Generation Controls
Users can customize output using:

### Audience Type
- Researcher  
- Student  
- Teacher  
- Common people  

### Word Count
- User-defined length  

### System Prompt Mode
- Default assistant  
- Custom instruction prompts  

---

## ğŸ—ºï¸ Project Workflow

### ğŸ§¾ 1 â€” User Input
- Blog topic or short content
- Select word count
- Choose audience type
- Choose system prompt mode

### ğŸ¤– 2 â€” Prompt Construction
- LangChain builds structured prompts
- System + user prompts combined

### ğŸ§  3 â€” Blog Generation
- Gemma3 (1B) runs locally via Ollama
- Generates blog content based on constraints

### ğŸŒ 4 â€” UI Output
- Streamlit displays generated blog
- Instant regeneration with new settings

---



---

<summary>ğŸ“¸ Click to view Streamlit UI screenshots</summary>

#### Home Page  
![Home Page](https://github.com/user-attachments/assets/467a4508-bb6e-4cc8-a3bf-b7b912b19288)



#### Results Page  1
![Result Page](https://github.com/user-attachments/assets/a9e49020-8a5b-4e57-a024-a5cfb0ae2609)




#### Results Page  1
![Result Page](https://github.com/user-attachments/assets/86ec1e5b-b712-45bb-a199-343b0dcff8e4)


---


## ğŸ“ Project Structure
```
Bank-Term-Deposit-Prediction/  
â”‚
â”‚ 
â”œâ”€â”€ Local LLM Code /  
â”‚   â””â”€â”€ chatbot.py 
â”‚  
â”œâ”€â”€ app/  
â”‚   â””â”€â”€ app.py  
â”‚  
â”œâ”€â”€ requirements.txt  
â””â”€â”€ README.md  

```
---

## ğŸ› ï¸ Installation & Execution

Clone repository:
```
git clone https://github.com/sarankumar74/Gemma3-LLM-Blog-Generator-app.git
cd Gemma3-LLM-Blog-Generator-app
```

Install dependencies:
```
pip install -r requirements.txt
```

Run Streamlit app:
```
streamlit run app/app.py
```
